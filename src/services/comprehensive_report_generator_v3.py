#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ARQV30 Enhanced v3.0 - Comprehensive Report Generator V3
Compilador de relat√≥rio final a partir dos m√≥dulos gerados
"""

import os
import logging
import json
from typing import Dict, Any, List
from datetime import datetime
from pathlib import Path

logger = logging.getLogger(__name__)

class ComprehensiveReportGeneratorV3:
    """Compilador de relat√≥rio final ultra robusto"""

    def __init__(self):
        """Inicializa o compilador"""
        # Ordem atualizada dos m√≥dulos, incluindo os novos m√≥dulos de CPL
        self.modules_order = [
            'anti_objecao',
            'avatars', 
            'concorrencia',
            'drivers_mentais',
            'funil_vendas',
            'insights_mercado',
            'palavras_chave',
            'plano_acao',
            'posicionamento',
            'pre_pitch',
            'predicoes_futuro',
            'provas_visuais',
            'metricas_conversao',
            'estrategia_preco',
            'canais_aquisicao',
            'cronograma_lancamento',
            # Novos m√≥dulos de CPL adicionados conforme instru√ß√µes do CPL.txt
            'cpl_protocol_1',
            'cpl_protocol_2',
            'cpl_protocol_3',
            'cpl_protocol_4',
            'cpl_protocol_5'
        ]

        # T√≠tulos atualizados, incluindo os novos m√≥dulos de CPL
        self.module_titles = {
            'anti_objecao': 'Sistema Anti-Obje√ß√£o',
            'avatars': 'Avatares do P√∫blico-Alvo',
            'concorrencia': 'An√°lise Competitiva',
            'drivers_mentais': 'Drivers Mentais',
            'funil_vendas': 'Funil de Vendas',
            'insights_mercado': 'Insights de Mercado',
            'palavras_chave': 'Estrat√©gia de Palavras-Chave',
            'plano_acao': 'Plano de A√ß√£o',
            'posicionamento': 'Estrat√©gia de Posicionamento',
            'pre_pitch': 'Estrutura de Pr√©-Pitch',
            'predicoes_futuro': 'Predi√ß√µes de Mercado',
            'provas_visuais': 'Sistema de Provas Visuais',
            'metricas_conversao': 'M√©tricas de Convers√£o',
            'estrategia_preco': 'Estrat√©gia de Precifica√ß√£o',
            'canais_aquisicao': 'Canais de Aquisi√ß√£o',
            'cronograma_lancamento': 'Cronograma de Lan√ßamento',
            # Novos t√≠tulos de m√≥dulos de CPL adicionados conforme instru√ß√µes do CPL.txt
            'cpl_protocol_1': 'Arquitetura do Evento Magn√©tico',
            'cpl_protocol_2': 'CPL1 - A Oportunidade Paralisante',
            'cpl_protocol_3': 'CPL2 - A Transforma√ß√£o Imposs√≠vel',
            'cpl_protocol_4': 'CPL3 - O Caminho Revolucion√°rio',
            'cpl_protocol_5': 'CPL4 - A Decis√£o Inevit√°vel'
        }

        logger.info("üìã Comprehensive Report Generator ULTRA ROBUSTO inicializado")

    def compile_final_markdown_report(self, session_id: str, predictive_insights: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Compila relat√≥rio final a partir dos m√≥dulos gerados

        Args:
            session_id: ID da sess√£o
            predictive_insights: Insights preditivos opcionais para incorporar ao relat√≥rio

        Returns:
            Dict com informa√ß√µes do relat√≥rio compilado
        """
        logger.info(f"üìã Compilando relat√≥rio final para sess√£o: {session_id}")

        try:
            # 1. Verifica estrutura de diret√≥rios
            session_dir = Path(f"analyses_data/{session_id}")
            modules_dir = session_dir / "modules"
            files_dir = Path(f"analyses_data/files/{session_id}")

            if not session_dir.exists():
                raise Exception(f"Diret√≥rio da sess√£o n√£o encontrado: {session_dir}")

            # 2. Carrega m√≥dulos dispon√≠veis
            available_modules = self._load_available_modules(modules_dir)

            # 3. Carrega screenshots dispon√≠veis
            screenshot_paths = self._load_screenshot_paths(files_dir)
            
            # 4. Carrega imagens virais extra√≠das
            viral_images = self._load_viral_images(session_id)

            # 5. Compila relat√≥rio (com insights preditivos e imagens virais)
            final_report = self._compile_report_content(
                session_id, 
                available_modules, 
                screenshot_paths,
                viral_images,
                predictive_insights
            )

            # 6. Salva relat√≥rio final
            report_path = self._save_final_report(session_id, final_report)

            # 7. Gera estat√≠sticas
            statistics = self._generate_report_statistics(
                available_modules, 
                screenshot_paths, 
                viral_images,
                final_report
            )

            logger.info(f"‚úÖ Relat√≥rio final compilado: {report_path}")

            return {
                "success": True,
                "session_id": session_id,
                "report_path": report_path,
                "modules_compiled": len(available_modules),
                "screenshots_included": len(screenshot_paths),
                "viral_images_included": len(viral_images),
                "estatisticas_relatorio": statistics,
                "timestamp": datetime.now().isoformat()
            }

        except Exception as e:
            logger.error(f"‚ùå Erro na compila√ß√£o: {e}")
            return {
                "success": False,
                "error": str(e),
                "session_id": session_id,
                "timestamp": datetime.now().isoformat()
            }

    def _load_available_modules(self, modules_dir: Path) -> Dict[str, str]:
        """Carrega m√≥dulos dispon√≠veis com diagn√≥stico detalhado"""
        available_modules = {}

        try:
            if not modules_dir.exists():
                logger.error(f"‚ùå Diret√≥rio de m√≥dulos n√£o existe: {modules_dir}")
                return available_modules

            # Lista todos os arquivos no diret√≥rio para diagn√≥stico
            all_files = list(modules_dir.glob("*"))
            logger.info(f"üìÅ Arquivos encontrados no diret√≥rio de m√≥dulos: {len(all_files)}")
            for file in all_files:
                logger.debug(f"   - {file.name}")

            modules_loaded = 0
            modules_failed = 0

            for module_name in self.modules_order:
                module_loaded = False
                
                # CORRE√á√ÉO: Tenta m√∫ltiplos formatos de nome de arquivo
                possible_files = [
                    modules_dir / f"{module_name}.md",
                    modules_dir / f"modulo_{module_name}.md",  # Formato usado pelo processador
                    modules_dir / f"{module_name}.json",
                    modules_dir / f"modulo_{module_name}.json"
                ]
                
                for module_file in possible_files:
                    if module_file.exists() and not module_loaded:
                        try:
                            if module_file.suffix == '.md':
                                with open(module_file, 'r', encoding='utf-8') as f:
                                    content = f.read()
                                    if content.strip():
                                        available_modules[module_name] = content
                                        logger.info(f"‚úÖ M√≥dulo MD carregado: {module_name} de {module_file.name} ({len(content)} chars)")
                                        modules_loaded += 1
                                        module_loaded = True
                                    else:
                                        logger.warning(f"‚ö†Ô∏è M√≥dulo MD vazio: {module_file.name}")
                            
                            elif module_file.suffix == '.json':
                                with open(module_file, 'r', encoding='utf-8') as f:
                                    json_content = json.load(f)
                                    # Converte o conte√∫do JSON em uma representa√ß√£o em texto
                                    content = json.dumps(json_content, indent=2, ensure_ascii=False)
                                    available_modules[module_name] = content
                                    logger.info(f"‚úÖ M√≥dulo JSON carregado: {module_name} de {module_file.name} ({len(content)} chars)")
                                    modules_loaded += 1
                                    module_loaded = True
                                    
                        except Exception as e:
                            logger.error(f"‚ùå Erro ao carregar {module_file.name}: {e}")
                            modules_failed += 1
                            logger.warning(f"‚ö†Ô∏è Erro ao carregar m√≥dulo JSON {module_name}: {e}")
                    else:
                        logger.warning(f"‚ö†Ô∏è M√≥dulo n√£o encontrado: {module_name}")
                        modules_failed += 1

            # CORRE√á√ÉO: Busca adicional por arquivos que podem ter sido perdidos
            logger.info("üîç Buscando m√≥dulos adicionais que podem ter sido perdidos...")
            
            # Busca por todos os arquivos .md e .json no diret√≥rio
            all_md_files = list(modules_dir.glob("*.md"))
            all_json_files = list(modules_dir.glob("*.json"))
            
            for file in all_md_files + all_json_files:
                # Extrai nome do m√≥dulo do arquivo
                file_name = file.stem
                
                # Remove prefixo "modulo_" se existir
                if file_name.startswith("modulo_"):
                    module_name = file_name[7:]  # Remove "modulo_"
                else:
                    module_name = file_name
                
                # Se n√£o foi carregado ainda, tenta carregar
                if module_name not in available_modules:
                    try:
                        if file.suffix == '.md':
                            with open(file, 'r', encoding='utf-8') as f:
                                content = f.read()
                                if content.strip():
                                    available_modules[module_name] = content
                                    logger.info(f"üîç M√≥dulo adicional MD encontrado: {module_name} ({len(content)} chars)")
                                    modules_loaded += 1
                        
                        elif file.suffix == '.json':
                            with open(file, 'r', encoding='utf-8') as f:
                                json_content = json.load(f)
                                content = json.dumps(json_content, indent=2, ensure_ascii=False)
                                available_modules[module_name] = content
                                logger.info(f"üîç M√≥dulo adicional JSON encontrado: {module_name} ({len(content)} chars)")
                                modules_loaded += 1
                                
                    except Exception as e:
                        logger.error(f"‚ùå Erro ao carregar m√≥dulo adicional {file.name}: {e}")

            logger.info(f"üìä RESUMO DE CARREGAMENTO DE M√ìDULOS:")
            logger.info(f"   ‚úÖ Carregados: {modules_loaded}")
            logger.info(f"   ‚ùå Falharam: {modules_failed}")
            logger.info(f"   üìã Total esperado: {len(self.modules_order)}")
            logger.info(f"   üìä Taxa de sucesso: {(modules_loaded/len(self.modules_order)*100):.1f}%")
            
            if modules_failed > 0:
                logger.error(f"‚ùå {modules_failed} m√≥dulos n√£o foram carregados - isso afetar√° o relat√≥rio final!")
            
            return available_modules

        except Exception as e:
            logger.error(f"‚ùå Erro ao carregar m√≥dulos: {e}")
            return available_modules

    def _load_screenshot_paths(self, files_dir: Path) -> List[str]:
        """Carrega caminhos dos screenshots"""
        screenshot_paths = []

        try:
            if not files_dir.exists():
                logger.warning(f"‚ö†Ô∏è Diret√≥rio de arquivos n√£o existe: {files_dir}")
                return screenshot_paths

            # Busca por arquivos PNG (screenshots)
            for screenshot_file in files_dir.glob("*.png"):
                relative_path = f"files/{files_dir.name}/{screenshot_file.name}"
                screenshot_paths.append(relative_path)
                logger.debug(f"üì∏ Screenshot encontrado: {screenshot_file.name}")

            logger.info(f"üì∏ {len(screenshot_paths)} screenshots encontrados")
            return screenshot_paths

        except Exception as e:
            logger.error(f"‚ùå Erro ao carregar screenshots: {e}")
            return screenshot_paths
    
    def _load_viral_images(self, session_id: str) -> List[Dict[str, Any]]:
        """Carrega imagens virais extra√≠das"""
        viral_images = []
        
        try:
            # Busca arquivo de metadados das imagens virais
            viral_images_dir = Path("viral_images")
            metadata_file = viral_images_dir / f"viral_images_metadata_{session_id}.json"
            
            if metadata_file.exists():
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                    viral_images = metadata.get('images', [])
                    
                logger.info(f"üñºÔ∏è {len(viral_images)} imagens virais carregadas")
            else:
                logger.info("üì∑ Nenhuma imagem viral encontrada para esta sess√£o")
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao carregar imagens virais: {e}")
            
        return viral_images

    def _compile_report_content(
        self, 
        session_id: str, 
        modules: Dict[str, str], 
        screenshots: List[str],
        viral_images: List[Dict[str, Any]],
        predictive_insights: Dict[str, Any] = None
    ) -> str:
        """Compila conte√∫do do relat√≥rio final com insights preditivos e imagens virais"""

        # Cabe√ßalho do relat√≥rio
        report = f"""# RELAT√ìRIO FINAL - ARQV30 Enhanced v3.0

**Sess√£o:** {session_id}  
**Gerado em:** {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}  
**M√≥dulos Compilados:** {len(modules)}/{len(self.modules_order)}  
**Screenshots Inclu√≠dos:** {len(screenshots)}  
**Imagens Virais Extra√≠das:** {len(viral_images)}

---

## SUM√ÅRIO EXECUTIVO

Este relat√≥rio consolida a an√°lise ultra-detalhada realizada pelo sistema ARQV30 Enhanced v3.0, contemplando {len(modules)} m√≥dulos especializados de an√°lise estrat√©gica.

### M√≥dulos Inclu√≠dos:
"""

        # Lista de m√≥dulos
        for i, module_name in enumerate(self.modules_order, 1):
            title = self.module_titles.get(module_name, module_name.replace('_', ' ').title())
            status = "‚úÖ" if module_name in modules else "‚ùå"
            report += f"{i}. {status} {title}\n"

        report += "\n---\n\n"

        # Adiciona screenshots se dispon√≠veis
        if screenshots:
            report += "## EVID√äNCIAS VISUAIS\n\n"
            for i, screenshot in enumerate(screenshots, 1):
                report += f"### Screenshot {i}\n"
                report += f"![Screenshot {i}]({screenshot})\n\n"
            report += "---\n\n"
        
        # Adiciona imagens virais extra√≠das
        if viral_images:
            report += "## IMAGENS VIRAIS EXTRA√çDAS\n\n"
            report += f"**Total de imagens extra√≠das:** {len(viral_images)}  \n"
            
            # Agrupa por plataforma
            by_platform = {}
            for img in viral_images:
                platform = img.get('platform', 'Unknown')
                if platform not in by_platform:
                    by_platform[platform] = []
                by_platform[platform].append(img)
            
            report += f"**Plataformas:** {', '.join(by_platform.keys())}  \n\n"
            
            # Mostra top 10 imagens por score de viralidade
            top_images = sorted(viral_images, key=lambda x: x.get('virality_score', 0), reverse=True)[:10]
            
            for i, img in enumerate(top_images, 1):
                report += f"### Imagem Viral {i} - {img.get('platform', 'Unknown')}\n\n"
                report += f"**T√≠tulo:** {img.get('title', 'Sem t√≠tulo')}  \n"
                report += f"**Score de Viralidade:** {img.get('virality_score', 0):.1f}/100  \n"
                
                metrics = img.get('engagement_metrics', {})
                if metrics:
                    report += "**M√©tricas de Engajamento:**  \n"
                    for metric, value in metrics.items():
                        if value > 0:
                            report += f"- {metric.title()}: {value:,}  \n"
                
                # Adiciona imagem se o caminho existir
                local_path = img.get('local_path', '')
                if local_path and os.path.exists(local_path):
                    # Converte para caminho relativo para o relat√≥rio
                    relative_path = local_path.replace('/workspace/project/v90/src/', '')
                    report += f"![Imagem Viral {i}]({relative_path})  \n\n"
                
                report += "---\n\n"

        # SE√á√ÉO DE INSIGHTS PREDITIVOS E CEN√ÅRIOS FUTUROS
        if predictive_insights and predictive_insights.get("success", False):
            report += self._compile_predictive_insights_section(predictive_insights)

        # Compila m√≥dulos na ordem definida
        for module_name in self.modules_order:
            if module_name in modules:
                title = self.module_titles.get(module_name, module_name.replace('_', ' ').title())
                report += f"## {title}\n\n"
                
                # Trata m√≥dulos CPL de forma especial (JSON)
                if module_name.startswith('cpl_protocol_'):
                    try:
                        # Tenta parsear o conte√∫do como JSON
                        module_content = json.loads(modules[module_name])
                        report += self._format_cpl_module_content(module_content)
                    except json.JSONDecodeError:
                        # Se n√£o for JSON v√°lido, adiciona o conte√∫do como est√°
                        report += modules[module_name]
                else:
                    # M√≥dulos normais em Markdown
                    report += modules[module_name]
                
                report += "\n\n---\n\n"

        # Rodap√©
        report += f"""
## INFORMA√á√ïES T√âCNICAS

**Sistema:** ARQV30 Enhanced v3.0  
**Sess√£o:** {session_id}  
**Data de Compila√ß√£o:** {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}  
**M√≥dulos Processados:** {len(modules)}/{len(self.modules_order)}  
**Status:** {'Completo' if len(modules) == len(self.modules_order) else 'Parcial'}

### Estat√≠sticas de Compila√ß√£o:
- ‚úÖ Sucessos: {len(modules)}
- ‚ùå Falhas: {len(self.modules_order) - len(modules)}
- üìä Taxa de Sucesso: {(len(modules)/len(self.modules_order)*100):.1f}%

---

*Relat√≥rio compilado automaticamente pelo ARQV30 Enhanced v3.0*
"""

        return report

    def _format_cpl_module_content(self, cpl_content: Dict[str, Any]) -> str:
        """Formata o conte√∫do de um m√≥dulo CPL para exibi√ß√£o no relat√≥rio"""
        try:
            formatted_content = ""
            
            # Adiciona t√≠tulo e descri√ß√£o se dispon√≠veis
            if 'titulo' in cpl_content:
                formatted_content += f"**{cpl_content['titulo']}**\n\n"
            
            if 'descricao' in cpl_content:
                formatted_content += f"{cpl_content['descricao']}\n\n"
            
            # Adiciona fases se dispon√≠veis
            if 'fases' in cpl_content:
                for fase_key, fase_data in cpl_content['fases'].items():
                    if isinstance(fase_data, dict):
                        # T√≠tulo da fase
                        if 'titulo' in fase_data:
                            formatted_content += f"### {fase_data['titulo']}\n\n"
                        
                        # Descri√ß√£o da fase
                        if 'descricao' in fase_data:
                            formatted_content += f"{fase_data['descricao']}\n\n"
                        
                        # Outros campos da fase
                        for key, value in fase_data.items():
                            if key not in ['titulo', 'descricao']:
                                if isinstance(value, str):
                                    formatted_content += f"**{key.replace('_', ' ').title()}:** {value}\n\n"
                                elif isinstance(value, list):
                                    formatted_content += f"**{key.replace('_', ' ').title()}:**\n"
                                    for item in value:
                                        if isinstance(item, str):
                                            formatted_content += f"- {item}\n"
                                        elif isinstance(item, dict):
                                            formatted_content += f"- {json.dumps(item, ensure_ascii=False)}\n"
                                    formatted_content += "\n"
                                elif isinstance(value, dict):
                                    formatted_content += f"**{key.replace('_', ' ').title()}:**\n"
                                    for sub_key, sub_value in value.items():
                                        formatted_content += f"  - {sub_key}: {sub_value}\n"
                                    formatted_content += "\n"
                    
            # Adiciona considera√ß√µes finais se dispon√≠veis
            if 'consideracoes_finais' in cpl_content:
                formatted_content += "### Considera√ß√µes Finais\n\n"
                for key, value in cpl_content['consideracoes_finais'].items():
                    if isinstance(value, str):
                        formatted_content += f"**{key.replace('_', ' ').title()}:** {value}\n\n"
                    elif isinstance(value, list):
                        formatted_content += f"**{key.replace('_', ' ').title()}:**\n"
                        for item in value:
                            formatted_content += f"- {item}\n"
                        formatted_content += "\n"
            
            return formatted_content
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao formatar conte√∫do CPL: {e}")
            return f"*Erro ao formatar conte√∫do do m√≥dulo CPL: {str(e)}*\n\n{json.dumps(cpl_content, indent=2, ensure_ascii=False)}"

    def _save_final_report(self, session_id: str, report_content: str) -> str:
        """Salva relat√≥rio final"""
        try:
            # Salva relat√≥rio compilado
            os.makedirs(f"analyses_data/{session_id}", exist_ok=True)
            final_report_path = f"analyses_data/{session_id}/relatorio_final.md"

            with open(final_report_path, 'w', encoding='utf-8') as f:
                f.write(report_content)

            return str(final_report_path)

        except Exception as e:
            logger.error(f"‚ùå Erro ao salvar relat√≥rio: {e}")
            raise

    def _generate_report_statistics(
        self, 
        modules: Dict[str, str], 
        screenshots: List[str], 
        viral_images: List[Dict[str, Any]],
        report_content: str
    ) -> Dict[str, Any]:
        """Gera estat√≠sticas do relat√≥rio"""
        
        # Estat√≠sticas das imagens virais
        viral_stats = {
            "total_images": len(viral_images),
            "by_platform": {},
            "average_virality_score": 0.0,
            "total_engagement": 0
        }
        
        if viral_images:
            # Agrupa por plataforma
            for img in viral_images:
                platform = img.get('platform', 'Unknown')
                if platform not in viral_stats["by_platform"]:
                    viral_stats["by_platform"][platform] = 0
                viral_stats["by_platform"][platform] += 1
            
            # Calcula score m√©dio
            scores = [img.get('virality_score', 0) for img in viral_images]
            viral_stats["average_virality_score"] = sum(scores) / len(scores) if scores else 0
            
            # Calcula engajamento total
            for img in viral_images:
                metrics = img.get('engagement_metrics', {})
                viral_stats["total_engagement"] += sum(metrics.values())

        return {
            "total_modules": len(self.modules_order),
            "modules_compiled": len(modules),
            "modules_missing": len(self.modules_order) - len(modules),
            "success_rate": (len(modules) / len(self.modules_order)) * 100,
            "screenshots_included": len(screenshots),
            "viral_images_stats": viral_stats,
            "total_characters": len(report_content),
            "estimated_pages": len(report_content) // 2000,  # ~2000 chars por p√°gina
            "compilation_timestamp": datetime.now().isoformat(),
            "paginas_estimadas": max(20, len(report_content) // 2000),  # M√≠nimo 20 p√°ginas
            "secoes_geradas": len(modules),
            "taxa_completude": (len(modules) / len(self.modules_order)) * 100
        }

    def generate_final_report(self, session_id: str) -> Dict[str, Any]:
        """M√©todo de compatibilidade"""
        return self.compile_final_markdown_report(session_id)

    def generate_detailed_report(
        self, 
        massive_data: Dict[str, Any], 
        modules_data: Dict[str, Any], 
        context: Dict[str, Any], 
        session_id: str
    ) -> Dict[str, Any]:
        """Gera relat√≥rio detalhado (m√©todo de compatibilidade)"""
        return self.compile_final_markdown_report(session_id)

    def _compile_predictive_insights_section(self, predictive_insights: Dict[str, Any]) -> str:
        """Compila se√ß√£o de insights preditivos e cen√°rios futuros"""
        
        section = """## üîÆ AN√ÅLISE PREDITIVA E CEN√ÅRIOS FUTUROS

### Metodologia de An√°lise Preditiva
Esta se√ß√£o apresenta insights avan√ßados gerados atrav√©s de an√°lise preditiva ultra-avan√ßada, utilizando t√©cnicas de machine learning, processamento de linguagem natural e modelagem estat√≠stica para projetar cen√°rios futuros e identificar oportunidades estrat√©gicas.

"""
        
        # Insights Textuais
        if "textual_insights" in predictive_insights:
            textual = predictive_insights["textual_insights"]
            section += "### üìä Insights Textuais Avan√ßados\n\n"
            
            if "entities_found" in textual and textual["entities_found"]:
                section += "**Entidades-Chave Identificadas:**\n"
                entities = textual["entities_found"]
                for entity, count in list(entities.items())[:10]:
                    section += f"- {entity}: {count} men√ß√µes\n"
                section += "\n"
            
            if "total_documents_processed" in textual:
                section += f"**Documentos Analisados:** {textual['total_documents_processed']}\n"
                section += f"**Palavras Processadas:** {textual.get('total_words_analyzed', 'N/A')}\n\n"
        
        # Previs√µes
        if "predictions" in predictive_insights:
            predictions = predictive_insights["predictions"]
            section += "### üéØ Previs√µes Estrat√©gicas\n\n"
            
            if "market_trends" in predictions:
                trends = predictions["market_trends"]
                section += "**Tend√™ncias de Mercado Previstas:**\n"
                for trend in trends.get("predicted_trends", [])[:5]:
                    if isinstance(trend, dict):
                        section += f"- {trend.get('trend', 'Tend√™ncia')}: {trend.get('probability', 'N/A')}% de probabilidade\n"
                    else:
                        section += f"- {trend}\n"
                section += "\n"
            
            if "growth_projections" in predictions:
                growth = predictions["growth_projections"]
                section += "**Proje√ß√µes de Crescimento:**\n"
                section += f"- Crescimento Estimado (3 meses): {growth.get('short_term', 'N/A')}\n"
                section += f"- Crescimento Estimado (12 meses): {growth.get('long_term', 'N/A')}\n"
                section += f"- Confian√ßa da Previs√£o: {growth.get('confidence', 'N/A')}\n\n"
        
        # Cen√°rios
        if "scenarios" in predictive_insights:
            scenarios = predictive_insights["scenarios"]
            section += "### üó∫Ô∏è Cen√°rios Futuros Modelados\n\n"
            
            for scenario_name, scenario_data in scenarios.items():
                if isinstance(scenario_data, dict) and scenario_name != "methodology":
                    section += f"**Cen√°rio {scenario_name.title()}:**\n"
                    section += f"- Probabilidade: {scenario_data.get('probability', 'N/A')}\n"
                    section += f"- Impacto: {scenario_data.get('impact', 'N/A')}\n"
                    section += f"- Descri√ß√£o: {scenario_data.get('description', 'N/A')}\n\n"
        
        # Avalia√ß√£o de Riscos
        if "risk_assessment" in predictive_insights:
            risks = predictive_insights["risk_assessment"]
            section += "### ‚öñÔ∏è Avalia√ß√£o de Riscos e Oportunidades\n\n"
            
            if "identified_risks" in risks:
                section += "**Riscos Identificados:**\n"
                for risk in risks["identified_risks"][:5]:
                    if isinstance(risk, dict):
                        section += f"- {risk.get('risk', 'Risco')}: {risk.get('severity', 'N/A')} (Probabilidade: {risk.get('probability', 'N/A')})\n"
                    else:
                        section += f"- {risk}\n"
                section += "\n"
            
            if "opportunities" in risks:
                section += "**Oportunidades Estrat√©gicas:**\n"
                for opp in risks["opportunities"][:5]:
                    if isinstance(opp, dict):
                        section += f"- {opp.get('opportunity', 'Oportunidade')}: {opp.get('potential', 'N/A')} (Viabilidade: {opp.get('feasibility', 'N/A')})\n"
                    else:
                        section += f"- {opp}\n"
                section += "\n"
        
        # Recomenda√ß√µes Estrat√©gicas
        if "strategic_recommendations" in predictive_insights:
            recommendations = predictive_insights["strategic_recommendations"]
            section += "### üí° Recomenda√ß√µes Estrat√©gicas Baseadas em IA\n\n"
            
            if "immediate_actions" in recommendations:
                section += "**A√ß√µes Imediatas (0-30 dias):**\n"
                for action in recommendations["immediate_actions"][:5]:
                    if isinstance(action, dict):
                        section += f"- {action.get('action', 'A√ß√£o')}: {action.get('description', 'N/A')}\n"
                    else:
                        section += f"- {action}\n"
                section += "\n"
            
            if "medium_term_actions" in recommendations:
                section += "**A√ß√µes de M√©dio Prazo (1-6 meses):**\n"
                for action in recommendations["medium_term_actions"][:5]:
                    if isinstance(action, dict):
                        section += f"- {action.get('action', 'A√ß√£o')}: {action.get('description', 'N/A')}\n"
                    else:
                        section += f"- {action}\n"
                section += "\n"
        
        # M√©tricas de Confian√ßa
        if "confidence_metrics" in predictive_insights:
            confidence = predictive_insights["confidence_metrics"]
            section += "### üìè M√©tricas de Confian√ßa da An√°lise\n\n"
            section += f"**Confian√ßa Geral:** {confidence.get('overall_confidence', 'N/A')}\n"
            section += f"**Qualidade dos Dados:** {confidence.get('data_quality_score', 'N/A')}\n"
            section += f"**Cobertura da An√°lise:** {confidence.get('analysis_coverage', 'N/A')}\n\n"
        
        section += "---\n\n"
        return section

# Inst√¢ncia global
comprehensive_report_generator_v3 = ComprehensiveReportGeneratorV3()
